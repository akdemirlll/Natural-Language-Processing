{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "# Tab delimiting is the best practice when reading from text files\n",
    "# No one inserts a tab when writing a review\n",
    "data = pd.read_csv('Restaurant_Reviews.tsv', delimiter = '\\t') #\\t means tab, quouting =3 ignores double quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked\n",
       "0                             Wow... Loved this place.      1\n",
       "1                                   Crust is not good.      0\n",
       "2            Not tasty and the texture was just nasty.      0\n",
       "3    Stopped by during the late May bank holiday of...      1\n",
       "4    The selection on the menu was great and so wer...      1\n",
       "..                                                 ...    ...\n",
       "995  I think food should have flavor and texture an...      0\n",
       "996                           Appetite instantly gone.      0\n",
       "997  Overall I was not impressed and would not go b...      0\n",
       "998  The whole experience was underwhelming, and I ...      0\n",
       "999  Then, as if I hadn't wasted enough of my life ...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Liked.unique() #Make sure there's no review under `Liked' column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the 'Liked' column, we have 1s and 0s, respectively indicating whether a review is positive or negative.\n",
    "\n",
    "### Stemming: combine similar words like 'loved' or 'lovely' together into one subgroup: 'love'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'univers'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PorterStemmer().stem('universe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'univers'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PorterStemmer().stem('university')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tailor'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PorterStemmer().stem('tailor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wow... Loved this place.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Review'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the texts\n",
    "\n",
    "import re\n",
    "\n",
    "review = re.sub('[^a-zA-Z^]',' ', data['Review'][0]) #Omits numbers and other characters, leaving only letters (for the 1st review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wow    Loved this place '"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review #Punctuation etc. is removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wow    loved this place '"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = review.lower() #All letters are made lowercase\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\berk_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords') # Download stopwords so irrelevant words won't affect our algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wow', 'loved', 'this', 'place']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem here is, review is a string, not a list. So we need to split review into different words\n",
    "# Quite easy:\n",
    "\n",
    "review = review.split()\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "# review = [word for word in review if not word in set(stopwords.words('english'))] \n",
    "# obsolete\n",
    "#omit designated stopwords from the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('ENGLISH')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wow', 'loved', 'this', 'place']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PorterStemmer().stem('universe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We just need the roots of the words, otherwise our algorithm would have problems\n",
    "# Every word with a suffix would need its own columns\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "review = [ps.stem(word) for word in review if not word in stops] \n",
    "#in addition to omitting stopwords, we also take only roots of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wow', 'love', 'place']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wow love place'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put our review back together into one single string\n",
    "review = ' '.join(review)\n",
    "review\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               Wow... Loved this place.\n",
       "1                                     Crust is not good.\n",
       "2              Not tasty and the texture was just nasty.\n",
       "3      Stopped by during the late May bank holiday of...\n",
       "4      The selection on the menu was great and so wer...\n",
       "                             ...                        \n",
       "995    I think food should have flavor and texture an...\n",
       "996                             Appetite instantly gone.\n",
       "997    Overall I was not impressed and would not go b...\n",
       "998    The whole experience was underwhelming, and I ...\n",
       "999    Then, as if I hadn't wasted enough of my life ...\n",
       "Name: Review, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 237 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Let's apply what we've done so far for the first review to all reviews by using a for loop\n",
    "# initialize a new list for our clean reviews\n",
    "corpus = []\n",
    "stops = set(stopwords.words('english'))\n",
    "stops.remove('not')\n",
    "\n",
    "\n",
    "for i in range(0, len(data)):\n",
    "    review = re.sub('[^a-zA-Z^]',' ', data['Review'][i])  # Remove punctuation\n",
    "    review = review.lower()                               # Lowercase\n",
    "    review = review.split()                               # Break down into lists\n",
    "    review = [word for word in review if not word in stops]  # Clean stopwords and stemming\n",
    "    review = [ps.stem(word) for word in review]  # Clean stopwords and stemming\n",
    "    review = ' '.join(review)                             # Join on space\n",
    "    corpus.append(review)                                 # Append to corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Clean</th>\n",
       "      <th>Like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>wow love place</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>crust not good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>not tasti textur nasti</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>stop late may bank holiday rick steve recommen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>select menu great price</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>think food flavor textur lack</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>appetit instantli gone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>overal not impress would not go back</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>whole experi underwhelm think go ninja sushi n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>wast enough life pour salt wound draw time too...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Actual  \\\n",
       "0                             Wow... Loved this place.   \n",
       "1                                   Crust is not good.   \n",
       "2            Not tasty and the texture was just nasty.   \n",
       "3    Stopped by during the late May bank holiday of...   \n",
       "4    The selection on the menu was great and so wer...   \n",
       "..                                                 ...   \n",
       "995  I think food should have flavor and texture an...   \n",
       "996                           Appetite instantly gone.   \n",
       "997  Overall I was not impressed and would not go b...   \n",
       "998  The whole experience was underwhelming, and I ...   \n",
       "999  Then, as if I hadn't wasted enough of my life ...   \n",
       "\n",
       "                                                 Clean  Like  \n",
       "0                                       wow love place     1  \n",
       "1                                       crust not good     0  \n",
       "2                               not tasti textur nasti     0  \n",
       "3    stop late may bank holiday rick steve recommen...     1  \n",
       "4                              select menu great price     1  \n",
       "..                                                 ...   ...  \n",
       "995                      think food flavor textur lack     0  \n",
       "996                             appetit instantli gone     0  \n",
       "997               overal not impress would not go back     0  \n",
       "998  whole experi underwhelm think go ninja sushi n...     0  \n",
       "999  wast enough life pour salt wound draw time too...     0  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Actual': data['Review'],\n",
    "              'Clean': corpus,\n",
    "              'Like': data['Liked']})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From here we are going to create a classification model<br> which classifies the reviews into the groups of 'Liked' or 'Disliked' by analyzing the words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvt = CountVectorizer(max_features=1500) # limiting the numbers of features to filter out irrelevant words  \n",
    "# There is an option to preprocess the text within CountVectorizer\n",
    "# However, preprocessing the data manually gives more flexibility, especially in the cases where one works with the webpages(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cvt.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Review'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolut</th>\n",
       "      <th>absolutley</th>\n",
       "      <th>accid</th>\n",
       "      <th>accommod</th>\n",
       "      <th>accomod</th>\n",
       "      <th>accordingli</th>\n",
       "      <th>account</th>\n",
       "      <th>ach</th>\n",
       "      <th>acknowledg</th>\n",
       "      <th>across</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yellowtail</th>\n",
       "      <th>yelper</th>\n",
       "      <th>yet</th>\n",
       "      <th>yucki</th>\n",
       "      <th>yukon</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummi</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 1500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     absolut  absolutley  accid  accommod  accomod  accordingli  account  ach  \\\n",
       "0          0           0      0         0        0            0        0    0   \n",
       "1          0           0      0         0        0            0        0    0   \n",
       "2          0           0      0         0        0            0        0    0   \n",
       "3          0           0      0         0        0            0        0    0   \n",
       "4          0           0      0         0        0            0        0    0   \n",
       "..       ...         ...    ...       ...      ...          ...      ...  ...   \n",
       "995        0           0      0         0        0            0        0    0   \n",
       "996        0           0      0         0        0            0        0    0   \n",
       "997        0           0      0         0        0            0        0    0   \n",
       "998        0           0      0         0        0            0        0    0   \n",
       "999        0           0      0         0        0            0        0    0   \n",
       "\n",
       "     acknowledg  across  ...  year  yellow  yellowtail  yelper  yet  yucki  \\\n",
       "0             0       0  ...     0       0           0       0    0      0   \n",
       "1             0       0  ...     0       0           0       0    0      0   \n",
       "2             0       0  ...     0       0           0       0    0      0   \n",
       "3             0       0  ...     0       0           0       0    0      0   \n",
       "4             0       0  ...     0       0           0       0    0      0   \n",
       "..          ...     ...  ...   ...     ...         ...     ...  ...    ...   \n",
       "995           0       0  ...     0       0           0       0    0      0   \n",
       "996           0       0  ...     0       0           0       0    0      0   \n",
       "997           0       0  ...     0       0           0       0    0      0   \n",
       "998           0       0  ...     0       0           0       0    0      0   \n",
       "999           0       0  ...     0       0           0       0    0      0   \n",
       "\n",
       "     yukon  yum  yummi  zero  \n",
       "0        0    0      0     0  \n",
       "1        0    0      0     0  \n",
       "2        0    0      0     0  \n",
       "3        0    0      0     0  \n",
       "4        0    0      0     0  \n",
       "..     ...  ...    ...   ...  \n",
       "995      0    0      0     0  \n",
       "996      0    0      0     0  \n",
       "997      0    0      0     0  \n",
       "998      0    0      0     0  \n",
       "999      0    0      0     0  \n",
       "\n",
       "[1000 rows x 1500 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X, columns=cvt.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.Liked.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try to understand the relation between the words appeared in a review and the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "metrics_compare = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we can use one of our previously used classification templates\n",
    "# In this exapmle, we will use Naive Bayes classifier\n",
    "\n",
    "# Splitting the dataset into Training Set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)\n",
    "\n",
    "#Feature Scaling\n",
    "# we don't need to do feature scaling as we mostly have zeros and ones\n",
    "'''from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)'''\n",
    "\n",
    "#Fitting the Naive Bayes Classifier \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "#Predicting the results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Making the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "cm_nb = confusion_matrix(y_test, y_pred)\n",
    "pd.DataFrame(cm_nb)\n",
    "\n",
    "#Other metrics\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "rec_score = recall_score(y_test, y_pred)\n",
    "prec_score = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "metrics = pd.Series([acc_score,prec_score,rec_score,f1] , name = str(classifier.__class__.__name__))\n",
    "\n",
    "metrics_compare = metrics_compare.append(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "# Fitting model to the train set\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy',\n",
    "                                    random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_decision_tree = confusion_matrix(y_test, y_pred)\n",
    "pd.DataFrame(cm_decision_tree)\n",
    "\n",
    "\n",
    "#Other metrics\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "rec_score = recall_score(y_test, y_pred)\n",
    "prec_score = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "metrics = pd.Series([acc_score,prec_score,rec_score,f1] , name = str(classifier.__class__.__name__))\n",
    "\n",
    "metrics_compare = metrics_compare.append(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "\n",
    "# Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.fit_transform(X_test)\n",
    "\n",
    "# Fitting model to the train set\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p=2)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_knn = confusion_matrix(y_test, y_pred)\n",
    "pd.DataFrame(cm_knn)\n",
    "\n",
    "#Other metrics\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "rec_score = recall_score(y_test, y_pred)\n",
    "prec_score = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "metrics = pd.Series([acc_score,prec_score,rec_score,f1] , name = str(classifier.__class__.__name__))\n",
    "\n",
    "metrics_compare = metrics_compare.append(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berk_\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Kernel SVM\n",
    "\n",
    "# Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.fit_transform(X_test)\n",
    "\n",
    "# Fitting model to the train set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf',\n",
    "                 degree = 4,     #ignored if selected any other kernel than poly\n",
    "                 random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm_kersvm = confusion_matrix(y_test, y_pred)\n",
    "pd.DataFrame(cm_kersvm)\n",
    "\n",
    "#Other metrics\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "rec_score = recall_score(y_test, y_pred)\n",
    "prec_score = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "metrics = pd.Series([acc_score,prec_score,rec_score,f1] , name = str(classifier.__class__.__name__))\n",
    "\n",
    "metrics_compare = metrics_compare.append(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berk_\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "# Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.fit_transform(X_test)\n",
    "\n",
    "# Fitting Logistic Regression to the train set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm_log_reg = confusion_matrix(y_test, y_pred)\n",
    "pd.DataFrame(cm_log_reg)\n",
    "\n",
    "#Other metrics\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "rec_score = recall_score(y_test, y_pred)\n",
    "prec_score = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "metrics = pd.Series([acc_score,prec_score,rec_score,f1] , name = str(classifier.__class__.__name__))\n",
    "\n",
    "metrics_compare = metrics_compare.append(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "# Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.fit_transform(X_test)\n",
    "\n",
    "# Fitting model to the train set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10,\n",
    "                                    criterion = 'entropy',\n",
    "                                    random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_svm = confusion_matrix(y_test, y_pred)\n",
    "pd.DataFrame(cm_svm)\n",
    "\n",
    "#Other metrics\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "rec_score = recall_score(y_test, y_pred)\n",
    "prec_score = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "metrics = pd.Series([acc_score,prec_score,rec_score,f1] , name = str(classifier.__class__.__name__))\n",
    "\n",
    "metrics_compare = metrics_compare.append(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berk_\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.fit_transform(X_test)\n",
    "\n",
    "# Fitting model to the train set\n",
    "from sklearn.svm import LinearSVC\n",
    "classifier = LinearSVC(\n",
    "                random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_svm = confusion_matrix(y_test, y_pred)\n",
    "pd.DataFrame(cm_svm)\n",
    "\n",
    "#Other metrics\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "rec_score = recall_score(y_test, y_pred)\n",
    "prec_score = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "metrics = pd.Series([acc_score,prec_score,rec_score,f1] , name = str(classifier.__class__.__name__))\n",
    "\n",
    "metrics_compare = metrics_compare.append(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CART\n",
    "# Fitting model to the train set\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'gini',\n",
    "                                    random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_decision_tree = confusion_matrix(y_test, y_pred)\n",
    "pd.DataFrame(cm_decision_tree)\n",
    "\n",
    "\n",
    "#Other metrics\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "rec_score = recall_score(y_test, y_pred)\n",
    "prec_score = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "metrics = pd.Series([acc_score,prec_score,rec_score,f1] , name = str(classifier.__class__.__name__))\n",
    "\n",
    "metrics_compare = metrics_compare.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.11093712, 0.11596012, 0.09794426]),\n",
       " 'score_time': array([0.00399661, 0.00299859, 0.00199938]),\n",
       " 'test_score': array([0.77310924, 0.74590164, 0.78448276])}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(classifier, X_train, y_train, cv=3,\n",
    "               scoring=make_scorer(precision_score)\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berk_\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>SVC</th>\n",
       "      <th>LinearSVC</th>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>fit_time</td>\n",
       "      <td>0.569745</td>\n",
       "      <td>0.026324</td>\n",
       "      <td>0.098297</td>\n",
       "      <td>0.061854</td>\n",
       "      <td>0.530674</td>\n",
       "      <td>0.888386</td>\n",
       "      <td>0.027021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>score_time</td>\n",
       "      <td>0.092955</td>\n",
       "      <td>0.065245</td>\n",
       "      <td>0.011002</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>1.021014</td>\n",
       "      <td>0.007334</td>\n",
       "      <td>1.656874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.828296</td>\n",
       "      <td>0.632678</td>\n",
       "      <td>0.781898</td>\n",
       "      <td>0.765212</td>\n",
       "      <td>0.613583</td>\n",
       "      <td>0.724575</td>\n",
       "      <td>0.667926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>0.764550</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.801587</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.462963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>test_f1</td>\n",
       "      <td>0.757158</td>\n",
       "      <td>0.691355</td>\n",
       "      <td>0.763405</td>\n",
       "      <td>0.782548</td>\n",
       "      <td>0.663275</td>\n",
       "      <td>0.680819</td>\n",
       "      <td>0.460729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.774667</td>\n",
       "      <td>0.657333</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.630667</td>\n",
       "      <td>0.697333</td>\n",
       "      <td>0.568000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                RandomForestClassifier  GaussianNB  DecisionTreeClassifier  \\\n",
       "fit_time                      0.569745    0.026324                0.098297   \n",
       "score_time                    0.092955    0.065245                0.011002   \n",
       "test_precision                0.828296    0.632678                0.781898   \n",
       "test_recall                   0.698413    0.764550                0.746032   \n",
       "test_f1                       0.757158    0.691355                0.763405   \n",
       "test_accuracy                 0.774667    0.657333                0.766667   \n",
       "\n",
       "                LogisticRegression       SVC  LinearSVC  KNeighborsClassifier  \n",
       "fit_time                  0.061854  0.530674   0.888386              0.027021  \n",
       "score_time                0.007333  1.021014   0.007334              1.656874  \n",
       "test_precision            0.765212  0.613583   0.724575              0.667926  \n",
       "test_recall               0.801587  0.722222   0.642857              0.462963  \n",
       "test_f1                   0.782548  0.663275   0.680819              0.460729  \n",
       "test_accuracy             0.776000  0.630667   0.697333              0.568000  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_X = StandardScaler()\n",
    "X_trains = sc_X.fit_transform(X_train)\n",
    "X_tests = sc_X.fit_transform(X_test)\n",
    "pd.concat([pd.DataFrame(cross_validate(classifier, X_trains, y_train, cv=3,\n",
    "               scoring=['precision', 'recall', 'f1', 'accuracy']\n",
    "              )).mean().rename(classifier.__class__.__name__)\n",
    "           for classifier in [RandomForestClassifier(n_estimators=100),\n",
    "                              GaussianNB(),\n",
    "                              DecisionTreeClassifier(),\n",
    "                              LogisticRegression(solver='lbfgs'),\n",
    "                              SVC(kernel='rbf', gamma='auto'),\n",
    "                              LinearSVC(),\n",
    "                              KNeighborsClassifier(n_neighbors=9)]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_compare = metrics_compare.rename(columns= {0: 'Accuracy Score',1: 'Precision Score',2: 'Recall Score',3: 'F1 Score'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVC</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>LinearSVC</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Accuracy Score</td>\n",
       "      <td>0.696000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.748000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Precision Score</td>\n",
       "      <td>0.627778</td>\n",
       "      <td>0.626506</td>\n",
       "      <td>0.715517</td>\n",
       "      <td>0.797980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Recall Score</td>\n",
       "      <td>0.926230</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.680328</td>\n",
       "      <td>0.647541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.697479</td>\n",
       "      <td>0.714932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      SVC  GaussianNB  LinearSVC  RandomForestClassifier\n",
       "Accuracy Score   0.696000    0.680000   0.712000                0.748000\n",
       "Precision Score  0.627778    0.626506   0.715517                0.797980\n",
       "Recall Score     0.926230    0.852459   0.680328                0.647541\n",
       "F1 Score         0.748344    0.722222   0.697479                0.714932"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_compare.transpose()[['SVC', 'GaussianNB', 'LinearSVC', 'RandomForestClassifier']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f99f3fd708>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_compare.plot(kind='bar', figsize=[15,10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
