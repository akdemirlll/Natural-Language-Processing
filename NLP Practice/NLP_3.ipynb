{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NLP Practice on DataFrames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data.txt', 'r')\n",
    "text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Project Gutenberg EBook of Man to Man, by Jackson Gregory\\n\\nThis eBook is for the use of anyone anywhere at no cost and with\\nalmost no restrictions whatsoever.  You may copy it, give it away or\\nre-use it under the terms of the Project Gutenberg License included\\nwith this eBook or online at www.gutenberg.org\\n\\n\\nTitle: Man to Man\\n\\nAuthor: Jackson Gregory\\n\\nRelease Date: July 29, 2006 [EBook #18933]\\n\\nLanguage: English\\n\\n\\n*** START OF THIS PROJECT GUTENBERG EBOOK MAN TO MAN ***\\n\\n\\n\\n\\nProduced by Al Haines\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[Frontispiece: The blazing heat was such that men and horses and steers\\nsuffered terribly.]\\n\\n\\n\\n\\n\\n\\nMAN TO MAN\\n\\n\\nBY\\n\\nJACKSON GREGORY\\n\\n\\n\\nAUTHOR OF\\n\\nJUDITH OF BLUE LAKE RANCH, THE BELLS OF SAN JUAN, SIX FEET FOUR, ETC.\\n\\n\\n\\n\\nILLUSTRATED BY\\n\\nJ. G. SHEPHERD\\n\\n\\n\\n\\n\\nGROSSET & DUNLAP\\n\\nPUBLISHERS -------- NEW YORK\\n\\n\\n\\n\\nCOPYRIGHT, 1920, BY\\n\\nCHARLES SCRIBNER'S SONS\\n\\n\\nPublished October, 1920\\n\\n\\n\\n\\nCONTENTS\\n\\n\\nCHAPTER\\n\\n     I. STEVE DIVES INTO DEEP WATERS\\n    II. MISS BLUE CLOAK KNOWS WHEN SHE'S BEAT\\n \""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78078"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9770"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Project Gutenberg EBook of Man to Man, by Jackson Gregory',\n",
       " '',\n",
       " 'This eBook is for the use of anyone anywhere at no cost and with',\n",
       " 'almost no restrictions whatsoever.  You may copy it, give it away or',\n",
       " 're-use it under the terms of the Project Gutenberg License included']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens=sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Project Gutenberg EBook of Man to Man, by Jackson Gregory\\n\\nThis eBook is for the use of anyone anywhere at no cost and with\\nalmost no restrictions whatsoever.',\n",
       " 'You may copy it, give it away or\\nre-use it under the terms of the Project Gutenberg License included\\nwith this eBook or online at www.gutenberg.org\\n\\n\\nTitle: Man to Man\\n\\nAuthor: Jackson Gregory\\n\\nRelease Date: July 29, 2006 [EBook #18933]\\n\\nLanguage: English\\n\\n\\n*** START OF THIS PROJECT GUTENBERG EBOOK MAN TO MAN ***\\n\\n\\n\\n\\nProduced by Al Haines\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[Frontispiece: The blazing heat was such that men and horses and steers\\nsuffered terribly.]',\n",
       " 'MAN TO MAN\\n\\n\\nBY\\n\\nJACKSON GREGORY\\n\\n\\n\\nAUTHOR OF\\n\\nJUDITH OF BLUE LAKE RANCH, THE BELLS OF SAN JUAN, SIX FEET FOUR, ETC.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5560"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"sentences\":sent_tokens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Project Gutenberg EBook of Man to Man, by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You may copy it, give it away or\\nre-use it un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAN TO MAN\\n\\n\\nBY\\n\\nJACKSON GREGORY\\n\\n\\n\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ILLUSTRATED BY\\n\\nJ. G. SHEPHERD\\n\\n\\n\\n\\n\\nGR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MISS BLUE CLOAK KNOWS WHEN SHE'S BEAT\\n   III.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences\n",
       "0  The Project Gutenberg EBook of Man to Man, by ...\n",
       "1  You may copy it, give it away or\\nre-use it un...\n",
       "2  MAN TO MAN\\n\\n\\nBY\\n\\nJACKSON GREGORY\\n\\n\\n\\nA...\n",
       "3  ILLUSTRATED BY\\n\\nJ. G. SHEPHERD\\n\\n\\n\\n\\n\\nGR...\n",
       "4     MISS BLUE CLOAK KNOWS WHEN SHE'S BEAT\\n   III."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5560, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(data):\n",
    "    \n",
    "    #1. Tokenize\n",
    "    text_tokens = word_tokenize(data)   #removed the .lower intentionaly to keep NNP s\n",
    "    \n",
    "    #2. Remove Puncs\n",
    "    tokens_without_punc = [w for w in text_tokens if w.isalpha()]\n",
    "    \n",
    "    #3. Removing Stopwords\n",
    "    tokens_without_sw = [t for t in tokens_without_punc if t not in stop_words]\n",
    "    \n",
    "    #4. lemma\n",
    "    text_cleaned = [lem.lemmatize(t) for t in tokens_without_sw]\n",
    "    \n",
    "    #joining\n",
    "    return \" \".join(text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentences_2\"] = df[\"sentences\"].apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>sentences_2</th>\n",
       "      <th>sentences_3</th>\n",
       "      <th>sentences_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Project Gutenberg EBook of Man to Man, by ...</td>\n",
       "      <td>The Project Gutenberg EBook Man Man Jackson Gr...</td>\n",
       "      <td>[project, gutenberg, ebook, man, man, jackson,...</td>\n",
       "      <td>[(project, NN), (gutenberg, NN), (ebook, NN), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You may copy it, give it away or\\nre-use it un...</td>\n",
       "      <td>You may copy give away term Project Gutenberg ...</td>\n",
       "      <td>[may, copy, give, away, term, project, gutenbe...</td>\n",
       "      <td>[(may, MD), (copy, VB), (give, VB), (away, RP)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAN TO MAN\\n\\n\\nBY\\n\\nJACKSON GREGORY\\n\\n\\n\\nA...</td>\n",
       "      <td>MAN TO MAN BY JACKSON GREGORY AUTHOR OF JUDITH...</td>\n",
       "      <td>[man, man, jackson, gregory, author, judith, b...</td>\n",
       "      <td>[(man, NN), (man, NN), (jackson, NN), (gregory...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ILLUSTRATED BY\\n\\nJ. G. SHEPHERD\\n\\n\\n\\n\\n\\nGR...</td>\n",
       "      <td>ILLUSTRATED BY SHEPHERD GROSSET DUNLAP PUBLISH...</td>\n",
       "      <td>[illustrated, shepherd, grosset, dunlap, publi...</td>\n",
       "      <td>[(illustrated, VBN), (shepherd, JJ), (grosset,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MISS BLUE CLOAK KNOWS WHEN SHE'S BEAT\\n   III.</td>\n",
       "      <td>MISS BLUE CLOAK KNOWS WHEN SHE BEAT III</td>\n",
       "      <td>[miss, blue, cloak, know, beat, iii]</td>\n",
       "      <td>[(miss, JJ), (blue, JJ), (cloak, NN), (know, V...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  \\\n",
       "0  The Project Gutenberg EBook of Man to Man, by ...   \n",
       "1  You may copy it, give it away or\\nre-use it un...   \n",
       "2  MAN TO MAN\\n\\n\\nBY\\n\\nJACKSON GREGORY\\n\\n\\n\\nA...   \n",
       "3  ILLUSTRATED BY\\n\\nJ. G. SHEPHERD\\n\\n\\n\\n\\n\\nGR...   \n",
       "4     MISS BLUE CLOAK KNOWS WHEN SHE'S BEAT\\n   III.   \n",
       "\n",
       "                                         sentences_2  \\\n",
       "0  The Project Gutenberg EBook Man Man Jackson Gr...   \n",
       "1  You may copy give away term Project Gutenberg ...   \n",
       "2  MAN TO MAN BY JACKSON GREGORY AUTHOR OF JUDITH...   \n",
       "3  ILLUSTRATED BY SHEPHERD GROSSET DUNLAP PUBLISH...   \n",
       "4            MISS BLUE CLOAK KNOWS WHEN SHE BEAT III   \n",
       "\n",
       "                                         sentences_3  \\\n",
       "0  [project, gutenberg, ebook, man, man, jackson,...   \n",
       "1  [may, copy, give, away, term, project, gutenbe...   \n",
       "2  [man, man, jackson, gregory, author, judith, b...   \n",
       "3  [illustrated, shepherd, grosset, dunlap, publi...   \n",
       "4               [miss, blue, cloak, know, beat, iii]   \n",
       "\n",
       "                                         sentences_4  \n",
       "0  [(project, NN), (gutenberg, NN), (ebook, NN), ...  \n",
       "1  [(may, MD), (copy, VB), (give, VB), (away, RP)...  \n",
       "2  [(man, NN), (man, NN), (jackson, NN), (gregory...  \n",
       "3  [(illustrated, VBN), (shepherd, JJ), (grosset,...  \n",
       "4  [(miss, JJ), (blue, JJ), (cloak, NN), (know, V...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Project Gutenberg EBook of Man to Man, by Jackson Gregory\\n\\nThis eBook is for the use of anyone anywhere at no cost and with\\nalmost no restrictions whatsoever.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Project Gutenberg EBook Man Man Jackson Gregory This eBook use anyone anywhere cost almost restriction whatsoever'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentences_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You may copy it, give it away or\\nre-use it under the terms of the Project Gutenberg License included\\nwith this eBook or online at www.gutenberg.org\\n\\n\\nTitle: Man to Man\\n\\nAuthor: Jackson Gregory\\n\\nRelease Date: July 29, 2006 [EBook #18933]\\n\\nLanguage: English\\n\\n\\n*** START OF THIS PROJECT GUTENBERG EBOOK MAN TO MAN ***\\n\\n\\n\\n\\nProduced by Al Haines\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[Frontispiece: The blazing heat was such that men and horses and steers\\nsuffered terribly.]'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You may copy give away term Project Gutenberg License included eBook online Title Man Man Author Jackson Gregory Release Date July EBook Language English START OF THIS PROJECT GUTENBERG EBOOK MAN TO MAN Produced Al Haines Frontispiece The blazing heat men horse steer suffered terribly'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentences_2[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PoST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentences_3\"]=df[\"sentences_2\"].apply(lambda x : x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>sentences_2</th>\n",
       "      <th>sentences_3</th>\n",
       "      <th>sentences_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Project Gutenberg EBook of Man to Man, by ...</td>\n",
       "      <td>The Project Gutenberg EBook Man Man Jackson Gr...</td>\n",
       "      <td>[The, Project, Gutenberg, EBook, Man, Man, Jac...</td>\n",
       "      <td>[(project, NN), (gutenberg, NN), (ebook, NN), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You may copy it, give it away or\\nre-use it un...</td>\n",
       "      <td>You may copy give away term Project Gutenberg ...</td>\n",
       "      <td>[You, may, copy, give, away, term, Project, Gu...</td>\n",
       "      <td>[(may, MD), (copy, VB), (give, VB), (away, RP)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAN TO MAN\\n\\n\\nBY\\n\\nJACKSON GREGORY\\n\\n\\n\\nA...</td>\n",
       "      <td>MAN TO MAN BY JACKSON GREGORY AUTHOR OF JUDITH...</td>\n",
       "      <td>[MAN, TO, MAN, BY, JACKSON, GREGORY, AUTHOR, O...</td>\n",
       "      <td>[(man, NN), (man, NN), (jackson, NN), (gregory...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ILLUSTRATED BY\\n\\nJ. G. SHEPHERD\\n\\n\\n\\n\\n\\nGR...</td>\n",
       "      <td>ILLUSTRATED BY SHEPHERD GROSSET DUNLAP PUBLISH...</td>\n",
       "      <td>[ILLUSTRATED, BY, SHEPHERD, GROSSET, DUNLAP, P...</td>\n",
       "      <td>[(illustrated, VBN), (shepherd, JJ), (grosset,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MISS BLUE CLOAK KNOWS WHEN SHE'S BEAT\\n   III.</td>\n",
       "      <td>MISS BLUE CLOAK KNOWS WHEN SHE BEAT III</td>\n",
       "      <td>[MISS, BLUE, CLOAK, KNOWS, WHEN, SHE, BEAT, III]</td>\n",
       "      <td>[(miss, JJ), (blue, JJ), (cloak, NN), (know, V...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  \\\n",
       "0  The Project Gutenberg EBook of Man to Man, by ...   \n",
       "1  You may copy it, give it away or\\nre-use it un...   \n",
       "2  MAN TO MAN\\n\\n\\nBY\\n\\nJACKSON GREGORY\\n\\n\\n\\nA...   \n",
       "3  ILLUSTRATED BY\\n\\nJ. G. SHEPHERD\\n\\n\\n\\n\\n\\nGR...   \n",
       "4     MISS BLUE CLOAK KNOWS WHEN SHE'S BEAT\\n   III.   \n",
       "\n",
       "                                         sentences_2  \\\n",
       "0  The Project Gutenberg EBook Man Man Jackson Gr...   \n",
       "1  You may copy give away term Project Gutenberg ...   \n",
       "2  MAN TO MAN BY JACKSON GREGORY AUTHOR OF JUDITH...   \n",
       "3  ILLUSTRATED BY SHEPHERD GROSSET DUNLAP PUBLISH...   \n",
       "4            MISS BLUE CLOAK KNOWS WHEN SHE BEAT III   \n",
       "\n",
       "                                         sentences_3  \\\n",
       "0  [The, Project, Gutenberg, EBook, Man, Man, Jac...   \n",
       "1  [You, may, copy, give, away, term, Project, Gu...   \n",
       "2  [MAN, TO, MAN, BY, JACKSON, GREGORY, AUTHOR, O...   \n",
       "3  [ILLUSTRATED, BY, SHEPHERD, GROSSET, DUNLAP, P...   \n",
       "4   [MISS, BLUE, CLOAK, KNOWS, WHEN, SHE, BEAT, III]   \n",
       "\n",
       "                                         sentences_4  \n",
       "0  [(project, NN), (gutenberg, NN), (ebook, NN), ...  \n",
       "1  [(may, MD), (copy, VB), (give, VB), (away, RP)...  \n",
       "2  [(man, NN), (man, NN), (jackson, NN), (gregory...  \n",
       "3  [(illustrated, VBN), (shepherd, JJ), (grosset,...  \n",
       "4  [(miss, JJ), (blue, JJ), (cloak, NN), (know, V...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentences_4\"]=df[\"sentences_3\"].apply(lambda x : nltk.pos_tag(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>sentences_2</th>\n",
       "      <th>sentences_3</th>\n",
       "      <th>sentences_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Project Gutenberg EBook of Man to Man, by ...</td>\n",
       "      <td>The Project Gutenberg EBook Man Man Jackson Gr...</td>\n",
       "      <td>[The, Project, Gutenberg, EBook, Man, Man, Jac...</td>\n",
       "      <td>[(The, DT), (Project, NNP), (Gutenberg, NNP), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You may copy it, give it away or\\nre-use it un...</td>\n",
       "      <td>You may copy give away term Project Gutenberg ...</td>\n",
       "      <td>[You, may, copy, give, away, term, Project, Gu...</td>\n",
       "      <td>[(You, PRP), (may, MD), (copy, VB), (give, VB)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAN TO MAN\\n\\n\\nBY\\n\\nJACKSON GREGORY\\n\\n\\n\\nA...</td>\n",
       "      <td>MAN TO MAN BY JACKSON GREGORY AUTHOR OF JUDITH...</td>\n",
       "      <td>[MAN, TO, MAN, BY, JACKSON, GREGORY, AUTHOR, O...</td>\n",
       "      <td>[(MAN, NN), (TO, NNP), (MAN, NNP), (BY, NNP), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ILLUSTRATED BY\\n\\nJ. G. SHEPHERD\\n\\n\\n\\n\\n\\nGR...</td>\n",
       "      <td>ILLUSTRATED BY SHEPHERD GROSSET DUNLAP PUBLISH...</td>\n",
       "      <td>[ILLUSTRATED, BY, SHEPHERD, GROSSET, DUNLAP, P...</td>\n",
       "      <td>[(ILLUSTRATED, VBN), (BY, NNP), (SHEPHERD, NNP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MISS BLUE CLOAK KNOWS WHEN SHE'S BEAT\\n   III.</td>\n",
       "      <td>MISS BLUE CLOAK KNOWS WHEN SHE BEAT III</td>\n",
       "      <td>[MISS, BLUE, CLOAK, KNOWS, WHEN, SHE, BEAT, III]</td>\n",
       "      <td>[(MISS, NNP), (BLUE, NNP), (CLOAK, NNP), (KNOW...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  \\\n",
       "0  The Project Gutenberg EBook of Man to Man, by ...   \n",
       "1  You may copy it, give it away or\\nre-use it un...   \n",
       "2  MAN TO MAN\\n\\n\\nBY\\n\\nJACKSON GREGORY\\n\\n\\n\\nA...   \n",
       "3  ILLUSTRATED BY\\n\\nJ. G. SHEPHERD\\n\\n\\n\\n\\n\\nGR...   \n",
       "4     MISS BLUE CLOAK KNOWS WHEN SHE'S BEAT\\n   III.   \n",
       "\n",
       "                                         sentences_2  \\\n",
       "0  The Project Gutenberg EBook Man Man Jackson Gr...   \n",
       "1  You may copy give away term Project Gutenberg ...   \n",
       "2  MAN TO MAN BY JACKSON GREGORY AUTHOR OF JUDITH...   \n",
       "3  ILLUSTRATED BY SHEPHERD GROSSET DUNLAP PUBLISH...   \n",
       "4            MISS BLUE CLOAK KNOWS WHEN SHE BEAT III   \n",
       "\n",
       "                                         sentences_3  \\\n",
       "0  [The, Project, Gutenberg, EBook, Man, Man, Jac...   \n",
       "1  [You, may, copy, give, away, term, Project, Gu...   \n",
       "2  [MAN, TO, MAN, BY, JACKSON, GREGORY, AUTHOR, O...   \n",
       "3  [ILLUSTRATED, BY, SHEPHERD, GROSSET, DUNLAP, P...   \n",
       "4   [MISS, BLUE, CLOAK, KNOWS, WHEN, SHE, BEAT, III]   \n",
       "\n",
       "                                         sentences_4  \n",
       "0  [(The, DT), (Project, NNP), (Gutenberg, NNP), ...  \n",
       "1  [(You, PRP), (may, MD), (copy, VB), (give, VB)...  \n",
       "2  [(MAN, NN), (TO, NNP), (MAN, NNP), (BY, NNP), ...  \n",
       "3  [(ILLUSTRATED, VBN), (BY, NNP), (SHEPHERD, NNP...  \n",
       "4  [(MISS, NNP), (BLUE, NNP), (CLOAK, NNP), (KNOW...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectorization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply to series not to df itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df[\"sentences_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aback', 'abandoned', 'abide', 'abiding', 'ability']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6130"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_count = vectorizer.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.DataFrame(X_train_count.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aback</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abide</th>\n",
       "      <th>abiding</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>about</th>\n",
       "      <th>abreast</th>\n",
       "      <th>abrupt</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>abruptness</th>\n",
       "      <th>absence</th>\n",
       "      <th>absent</th>\n",
       "      <th>absently</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abstraction</th>\n",
       "      <th>absurd</th>\n",
       "      <th>abundant</th>\n",
       "      <th>accelerator</th>\n",
       "      <th>accept</th>\n",
       "      <th>accepted</th>\n",
       "      <th>accepting</th>\n",
       "      <th>access</th>\n",
       "      <th>...</th>\n",
       "      <th>yeee</th>\n",
       "      <th>yell</th>\n",
       "      <th>yelled</th>\n",
       "      <th>yellin</th>\n",
       "      <th>yelling</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yes</th>\n",
       "      <th>yessir</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yets</th>\n",
       "      <th>yield</th>\n",
       "      <th>yielded</th>\n",
       "      <th>yielding</th>\n",
       "      <th>yonder</th>\n",
       "      <th>york</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>youngest</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourse</th>\n",
       "      <th>youth</th>\n",
       "      <th>youthful</th>\n",
       "      <th>zest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 6130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aback  abandoned  abide  abiding  ability  able  aboard  about  abreast  \\\n",
       "0      0          0      0        0        0     0       0      0        0   \n",
       "1      0          0      0        0        0     0       0      0        0   \n",
       "2      0          0      0        0        0     0       0      0        0   \n",
       "3      0          0      0        0        0     0       0      0        0   \n",
       "4      0          0      0        0        0     0       0      0        0   \n",
       "\n",
       "   abrupt  abruptly  abruptness  absence  absent  absently  absolute  \\\n",
       "0       0         0           0        0       0         0         0   \n",
       "1       0         0           0        0       0         0         0   \n",
       "2       0         0           0        0       0         0         0   \n",
       "3       0         0           0        0       0         0         0   \n",
       "4       0         0           0        0       0         0         0   \n",
       "\n",
       "   absolutely  abstraction  absurd  abundant  accelerator  accept  accepted  \\\n",
       "0           0            0       0         0            0       0         0   \n",
       "1           0            0       0         0            0       0         0   \n",
       "2           0            0       0         0            0       0         0   \n",
       "3           0            0       0         0            0       0         0   \n",
       "4           0            0       0         0            0       0         0   \n",
       "\n",
       "   accepting  access  ...  yeee  yell  yelled  yellin  yelling  yellow  yes  \\\n",
       "0          0       0  ...     0     0       0       0        0       0    0   \n",
       "1          0       0  ...     0     0       0       0        0       0    0   \n",
       "2          0       0  ...     0     0       0       0        0       0    0   \n",
       "3          0       0  ...     0     0       0       0        0       0    0   \n",
       "4          0       0  ...     0     0       0       0        0       0    0   \n",
       "\n",
       "   yessir  yesterday  yet  yets  yield  yielded  yielding  yonder  york  you  \\\n",
       "0       0          0    0     0      0        0         0       0     0    0   \n",
       "1       0          0    0     0      0        0         0       0     0    1   \n",
       "2       0          0    0     0      0        0         0       0     0    0   \n",
       "3       0          0    0     0      0        0         0       0     1    0   \n",
       "4       0          0    0     0      0        0         0       0     0    0   \n",
       "\n",
       "   young  youngest  your  yours  yourse  youth  youthful  zest  \n",
       "0      0         0     0      0       0      0         0     0  \n",
       "1      0         0     0      0       0      0         0     0  \n",
       "2      0         0     0      0       0      0         0     0  \n",
       "3      0         0     0      0       0      0         0     0  \n",
       "4      0         0     0      0       0      0         0     0  \n",
       "\n",
       "[5 rows x 6130 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5560, 6130)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tf-idf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vectorizer=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf_idf = tf_idf_vectorizer.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.DataFrame(X_train_tf_idf.toarray(), columns=tf_idf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aback</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abide</th>\n",
       "      <th>abiding</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>about</th>\n",
       "      <th>abreast</th>\n",
       "      <th>abrupt</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>abruptness</th>\n",
       "      <th>absence</th>\n",
       "      <th>absent</th>\n",
       "      <th>absently</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abstraction</th>\n",
       "      <th>absurd</th>\n",
       "      <th>abundant</th>\n",
       "      <th>accelerator</th>\n",
       "      <th>accept</th>\n",
       "      <th>accepted</th>\n",
       "      <th>accepting</th>\n",
       "      <th>access</th>\n",
       "      <th>...</th>\n",
       "      <th>yeee</th>\n",
       "      <th>yell</th>\n",
       "      <th>yelled</th>\n",
       "      <th>yellin</th>\n",
       "      <th>yelling</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yes</th>\n",
       "      <th>yessir</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yets</th>\n",
       "      <th>yield</th>\n",
       "      <th>yielded</th>\n",
       "      <th>yielding</th>\n",
       "      <th>yonder</th>\n",
       "      <th>york</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>youngest</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourse</th>\n",
       "      <th>youth</th>\n",
       "      <th>youthful</th>\n",
       "      <th>zest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 6130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aback  abandoned  abide  abiding  ability  able  aboard  about  abreast  \\\n",
       "0    0.0        0.0    0.0      0.0      0.0   0.0     0.0    0.0      0.0   \n",
       "1    0.0        0.0    0.0      0.0      0.0   0.0     0.0    0.0      0.0   \n",
       "2    0.0        0.0    0.0      0.0      0.0   0.0     0.0    0.0      0.0   \n",
       "3    0.0        0.0    0.0      0.0      0.0   0.0     0.0    0.0      0.0   \n",
       "4    0.0        0.0    0.0      0.0      0.0   0.0     0.0    0.0      0.0   \n",
       "\n",
       "   abrupt  abruptly  abruptness  absence  absent  absently  absolute  \\\n",
       "0     0.0       0.0         0.0      0.0     0.0       0.0       0.0   \n",
       "1     0.0       0.0         0.0      0.0     0.0       0.0       0.0   \n",
       "2     0.0       0.0         0.0      0.0     0.0       0.0       0.0   \n",
       "3     0.0       0.0         0.0      0.0     0.0       0.0       0.0   \n",
       "4     0.0       0.0         0.0      0.0     0.0       0.0       0.0   \n",
       "\n",
       "   absolutely  abstraction  absurd  abundant  accelerator  accept  accepted  \\\n",
       "0         0.0          0.0     0.0       0.0          0.0     0.0       0.0   \n",
       "1         0.0          0.0     0.0       0.0          0.0     0.0       0.0   \n",
       "2         0.0          0.0     0.0       0.0          0.0     0.0       0.0   \n",
       "3         0.0          0.0     0.0       0.0          0.0     0.0       0.0   \n",
       "4         0.0          0.0     0.0       0.0          0.0     0.0       0.0   \n",
       "\n",
       "   accepting  access  ...  yeee  yell  yelled  yellin  yelling  yellow  yes  \\\n",
       "0        0.0     0.0  ...   0.0   0.0     0.0     0.0      0.0     0.0  0.0   \n",
       "1        0.0     0.0  ...   0.0   0.0     0.0     0.0      0.0     0.0  0.0   \n",
       "2        0.0     0.0  ...   0.0   0.0     0.0     0.0      0.0     0.0  0.0   \n",
       "3        0.0     0.0  ...   0.0   0.0     0.0     0.0      0.0     0.0  0.0   \n",
       "4        0.0     0.0  ...   0.0   0.0     0.0     0.0      0.0     0.0  0.0   \n",
       "\n",
       "   yessir  yesterday  yet  yets  yield  yielded  yielding  yonder      york  \\\n",
       "0     0.0        0.0  0.0   0.0    0.0      0.0       0.0     0.0  0.000000   \n",
       "1     0.0        0.0  0.0   0.0    0.0      0.0       0.0     0.0  0.000000   \n",
       "2     0.0        0.0  0.0   0.0    0.0      0.0       0.0     0.0  0.000000   \n",
       "3     0.0        0.0  0.0   0.0    0.0      0.0       0.0     0.0  0.214756   \n",
       "4     0.0        0.0  0.0   0.0    0.0      0.0       0.0     0.0  0.000000   \n",
       "\n",
       "        you  young  youngest  your  yours  yourse  youth  youthful  zest  \n",
       "0  0.000000    0.0       0.0   0.0    0.0     0.0    0.0       0.0   0.0  \n",
       "1  0.081525    0.0       0.0   0.0    0.0     0.0    0.0       0.0   0.0  \n",
       "2  0.000000    0.0       0.0   0.0    0.0     0.0    0.0       0.0   0.0  \n",
       "3  0.000000    0.0       0.0   0.0    0.0     0.0    0.0       0.0   0.0  \n",
       "4  0.000000    0.0       0.0   0.0    0.0     0.0    0.0       0.0   0.0  \n",
       "\n",
       "[5 rows x 6130 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blenham       121.693580\n",
       "steve         119.792142\n",
       "packard       114.215786\n",
       "terry         102.879166\n",
       "said           91.987103\n",
       "                 ...    \n",
       "alteration      0.140733\n",
       "indirectly      0.140733\n",
       "indemnity       0.140733\n",
       "indemnify       0.140733\n",
       "deletion        0.140733\n",
       "Length: 6130, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "steve        542\n",
       "packard      541\n",
       "blenham      524\n",
       "man          445\n",
       "terry        409\n",
       "            ... \n",
       "richly         1\n",
       "formulate      1\n",
       "forming        1\n",
       "former         1\n",
       "duster         1\n",
       "Length: 6130, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
